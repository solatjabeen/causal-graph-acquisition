{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medical Records Classification\n",
    "\n",
    "##### How to use\n",
    "- Run all cells till Feature Vector section\n",
    "- Run any one feature vector to get test_vectors and doc_vectors along with pairwise dist calculations\n",
    "- For clustering, go the Clustering Analysis section, and run any one algorithm\n",
    "- Tune parameters as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import simple_icd_10_cm as icd\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.cluster import KMeans,AgglomerativeClustering,AffinityPropagation,Birch\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import gensim.models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.doc2vec import TaggedDocument,Doc2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "\n",
    "import collections\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'Data\\ERSampleforCoding_150322.xlsx')\n",
    "med_dict = pd.read_excel(r'Data\\medicalTermsDictionary (1).xlsx')\n",
    "med_dict = dict(zip(med_dict.Abbreviation, med_dict.Term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get all codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_codes = icd.get_all_codes(with_dots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_df = pd.DataFrame(all_codes,columns=['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_df['description'] = code_df['code'].apply(lambda x: icd.get_description(x))\n",
    "code_df['ancestor'] = code_df['code'].apply(lambda x: icd.get_ancestors(x))\n",
    "code_df['descendants'] = code_df['code'].apply(lambda x: icd.get_descendants(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = code_df[code_df.apply(lambda x: len(x['ancestor']),axis=1) == 0]\n",
    "filtered = filtered.drop_duplicates(['description'])\n",
    "filtered = filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in filtered.iterrows():\n",
    "    desc = [filtered.loc[c[0]].description]\n",
    "    for d in c[1]['descendants']:\n",
    "        desc.append(icd.get_description(d))\n",
    "    filtered.loc[c[0]].description = \" \".join(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'Data/data.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Golden Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_excel(r'Data\\Sample_HOPI.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "all_stopwords = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text):\n",
    "    doc = nlp(text)\n",
    "    sent = list()\n",
    "    for token in doc:\n",
    "        w = token.text.lower()\n",
    "        if w in med_dict.keys():\n",
    "            w = med_dict[w]\n",
    "        w = re.sub('[^A-Za-z\\s]+', '', w)\n",
    "        if not(token.is_space) and not(token.is_punct):\n",
    "            sent.append(w)\n",
    "            \n",
    "    sent= [word for word in sent if not word in all_stopwords]\n",
    "    return \" \".join(sent)\n",
    "\n",
    "modified = test_df['hopi_'].apply(lambda x: transformText(x))\n",
    "test_df['HOPI_modified'] = modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_df['HOPI_modified'].notna()]\n",
    "test_df = test_df[test_df['code'].notna()]\n",
    "test_df = test_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.to_csv('Data/test_df.csv',index=False)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAncestors(x):\n",
    "    index = 3\n",
    "    codes = x.split(',')\n",
    "    temp = list()\n",
    "    for c in codes:\n",
    "        i = c.strip()\n",
    "        while(len(i) > 0 and not(icd.is_valid_item(i))):\n",
    "            i = i[:-1]\n",
    "        \n",
    "        if len(i) == 0:\n",
    "            continue \n",
    "        if len(icd.get_ancestors(i)) < index:\n",
    "            temp.append(i)\n",
    "        else:\n",
    "            i = icd.get_ancestors(i)[-index]\n",
    "        temp.append(i)\n",
    "    \n",
    "    \n",
    "    return \",\".join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getAncestors('R50.9, R11.10, R52, M54.9, R05.9, K59.00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['code_modified'] = test_df['code'].apply(lambda x: getAncestors(x))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([df['HOPI_modified'],filtered['description']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "vectorizer.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = vectorizer.transform(filtered['description']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors = vectorizer.transform(test_df['HOPI_modified']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors = csr_matrix(doc_vectors)\n",
    "tsvd = TruncatedSVD(n_components=10)\n",
    "_ = tsvd.fit(doc_vectors)\n",
    "\n",
    "doc_vectors = tsvd.transform(doc_vectors)\n",
    "test_vectors = tsvd.transform(csr_matrix(test_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Average Word2Vec Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for line in self.data:\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield line.split(\" \")\n",
    "            \n",
    "vec_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sentences=MyCorpus(pd.concat([df['HOPI_modified'],filtered['description']])),\n",
    "                               window=15,\n",
    "                               vector_size=vec_size,\n",
    "                               min_count=5,\n",
    "                               epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocVec(doc):\n",
    "    tokens = nlp(doc)\n",
    "    vec = np.zeros(vec_size)\n",
    "    count = 1e-5\n",
    "    for t in tokens:\n",
    "        if not(t.is_space) and model.wv.has_index_for(t.text):\n",
    "            count += 1\n",
    "            vec += model.wv[t.text]\n",
    "    \n",
    "    return vec/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = np.zeros((vec_size,len(filtered['description'])))\n",
    "for n,d in enumerate(filtered['description']):\n",
    "    test_vectors[:,n] = getDocVec(d)\n",
    "    \n",
    "test_vectors = test_vectors.T\n",
    "\n",
    "doc_vectors = np.zeros((vec_size,len(test_df['HOPI_modified'])))\n",
    "for n,d in enumerate(test_df['HOPI_modified']):\n",
    "    doc_vectors[:,n] = getDocVec(d)\n",
    "    \n",
    "doc_vectors = doc_vectors.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PmC Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download from http://evexdb.org/pmresources/vec-space-models/\n",
    "model = KeyedVectors.load_word2vec_format('F:\\PmC-w2v.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocVec(doc):\n",
    "    tokens = nlp(doc)\n",
    "    vec = np.zeros(model.vector_size)\n",
    "    count = 1e-5\n",
    "    for t in tokens:\n",
    "        if not(t.is_space) and model.has_index_for(t.text):\n",
    "            count += 1\n",
    "            vec += model[t.text]\n",
    "    \n",
    "    return vec/count\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors = np.zeros((model.vector_size,len(test_df['HOPI_modified'])))\n",
    "for n,d in enumerate(test_df['HOPI_modified']):\n",
    "    doc_vectors[:,n] = getDocVec(d)\n",
    "    \n",
    "doc_vectors = doc_vectors.T\n",
    "\n",
    "test_vectors = np.zeros((model.vector_size,len(filtered['description'])))\n",
    "for n,d in enumerate(filtered['description']):\n",
    "    test_vectors[:,n] = getDocVec(d)\n",
    "    \n",
    "test_vectors = test_vectors.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pairwise_distances(doc_vectors,test_vectors,metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(i):\n",
    "    # selected = np.sort(dist[i,:])\n",
    "    # threshold = selected[0] + (0.1*selected[0]) #0.025,0.025,\n",
    "    # selected = selected[selected < threshold]\n",
    "    # nearest = list(zip(selected,np.argsort(dist)[i,:(selected.shape[0])]))\n",
    "    \n",
    "    n=8\n",
    "    nearest = list(zip(np.sort(dist)[i,:n],np.argsort(dist)[i,:n]))\n",
    "\n",
    "\n",
    "    temp = list()\n",
    "    for j in nearest:\n",
    "        code = filtered['code'][j[1]]\n",
    "        temp.append(code)\n",
    "        # print(code, icd.get_description(code),\"Score:\",j[0])\n",
    "    \n",
    "    return \",\".join(temp)\n",
    "\n",
    "test_df['predicted'] = list(map(get_labels,list(range(0,test_df.shape[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = []\n",
    "precision = []\n",
    "f_score = []\n",
    "\n",
    "for i in range(test_df.shape[0]):\n",
    "    s1 = set(test_df['code_modified'][i].split(\",\"))\n",
    "    s2 = set(test_df['predicted'][i].split(\",\"))\n",
    "\n",
    "    inter = len(s1.intersection(s2))\n",
    "    r = inter/len(s1)\n",
    "    recall.append(r)\n",
    "    p = inter/len(s2)\n",
    "    precision.append(p)\n",
    "\n",
    "    try:\n",
    "        f_score.append(2 * r * p/(r + p))\n",
    "    except:\n",
    "        f_score.append(0)\n",
    "    \n",
    "test_df['recall'] = recall\n",
    "test_df['precision'] = precision\n",
    "test_df['f_score'] = f_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_recall = test_df['recall'].mean()\n",
    "avg_prec = test_df['precision'].mean()\n",
    "avg_f_score = test_df['f_score'].mean()\n",
    "print(\"Recall: {}\\nPrecision: {}\\nF-Score: {}\".format(avg_recall,avg_prec,avg_f_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predicted'].apply(lambda x: len(x.split(\",\"))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0 #0,97,186\n",
    "# selected = np.sort(dist[i,:])\n",
    "# threshold = selected[0] + 0.01 #0.025\n",
    "# selected = selected[selected < threshold]\n",
    "# nearest = list(zip(selected,np.argsort(dist)[i,:(selected.shape[0])]))\n",
    "\n",
    "n=8\n",
    "nearest = list(zip(np.sort(dist)[i,:n],np.argsort(dist)[i,:n]))\n",
    "\n",
    "\n",
    "print('HOPI: ',test_df['hopi_'][i].replace(\"\\n\",\" \"),end=\"\\n\\n\")\n",
    "print(\"Actual Code\",test_df[\"code_modified\"][i],end=\"\\n\\n\")\n",
    "\n",
    "for j in nearest:\n",
    "    code = filtered['code'][j[1]]\n",
    "    print(\"{} - {} ({})\".format(code,icd.get_description(code),round(j[0],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = set(test_df['code_modified'][i].split(\",\"))\n",
    "s2 = set(test_df['predicted'][i].split(\",\"))\n",
    "\n",
    "inter = len(s1.intersection(s2))\n",
    "r = inter/len(s1)\n",
    "p = inter/len(s2)\n",
    "f_score = 0\n",
    "try:\n",
    "    f_score= 2 * r * p/(r + p)\n",
    "except:\n",
    "    f_score = 0\n",
    "    \n",
    "print(\"Precision: {}\\nRecall: {}\\nf_score: {}\".format(p,r,f_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sumaira's Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [['R68', 'R11', 'K59', 'R10', 'M54', 'R05'],\n",
    " ['R53'],\n",
    " ['T79', 'I64', 'R26', 'L89', 'R53'],\n",
    " [],\n",
    " ['R52', 'W01'],\n",
    " ['R20', 'R19', 'K92', 'R42'],\n",
    " ['R52', 'R10', 'R31', 'K59'],\n",
    " [],\n",
    " ['R11', 'K59', 'R42'],\n",
    " ['E66'],\n",
    " ['R11', 'K59'],\n",
    " ['I38', 'I46', 'H18', 'R09', 'R99', 'R10'],\n",
    " ['R22', 'B99', 'R19'],\n",
    " ['R06', 'R11', 'R10', 'A16'],\n",
    " ['R06', 'A16', 'K80', 'R09', 'I21', 'K75', 'R05'],\n",
    " [],\n",
    " ['N25', 'G82', 'S19', 'R19'],\n",
    " ['R06', 'R07', 'A16', 'T14', 'R10'],\n",
    " ['R11', 'R19'],\n",
    " ['R30', 'R19', 'N48', 'R36', 'N34'],\n",
    " ['N92', 'R19'],\n",
    " ['N25', 'A35', 'S92'],\n",
    " ['R19', 'K92', 'S09', 'R41'],\n",
    " ['R52', 'T65', 'R20', 'R19'],\n",
    " ['N05', 'K51', 'M54'],\n",
    " ['M47', 'K59', 'T14', 'R52', 'R40', 'M54'],\n",
    " ['J34', 'R04', 'T14', 'R52', 'Z72', 'A35'],\n",
    " ['N25', 'R04', 'A35'],\n",
    " ['R06', 'A16', 'R19', 'R55', 'I48', 'R11', 'R07', 'T14', 'I95', 'S00'],\n",
    " ['R63', 'R56', 'R19'],\n",
    " ['R19'],\n",
    " ['R10', 'R31', 'R19'],\n",
    " ['R52', 'M25', 'A16'],\n",
    " ['R06', 'A16', 'R19', 'E04', 'R27'],\n",
    " ['L29', 'L81', 'M17'],\n",
    " ['M25', 'R06', 'R11', 'R07', 'R10', 'R05'],\n",
    " ['R22', 'K64', 'K59', 'K62', 'E14'],\n",
    " ['R07', 'T14', 'R52', 'S72', 'W01'],\n",
    " ['R00', 'R11', 'R19', 'R10', 'A09'],\n",
    " ['L29', 'R19'],\n",
    " ['R82', 'R39', 'M54'],\n",
    " ['T14', 'S09', 'S80', 'R52', 'S02'],\n",
    " ['Z71', 'K59'],\n",
    " ['N25'],\n",
    " ['N32', 'N20', 'R39', 'N13'],\n",
    " ['E87', 'T14', 'E03', 'R31', 'R19'],\n",
    " ['R04', 'R68', 'R11', 'R19', 'E14'],\n",
    " ['R11', 'N13', 'R19', 'R52', 'R33', 'R53'],\n",
    " ['R22', 'N40', 'K80', 'R53', 'E14', 'E87', 'R68', 'R11', 'K59', 'A41'],\n",
    " ['N25', 'T14'],\n",
    " ['R51', 'R11', 'R50', 'R19', 'R42', 'R10'],\n",
    " ['R19', 'M43', 'R52', 'R26'],\n",
    " ['N93'],\n",
    " ['A97', 'R00', 'R05'],\n",
    " ['R68', 'R06', 'R50', 'K59', 'R19', 'J45'],\n",
    " ['R06', 'I46', 'R09', 'R99'],\n",
    " ['R10', 'R19'],\n",
    " ['R07', 'E87', 'R39'],\n",
    " ['N25', 'M86', 'M79'],\n",
    " ['K40'],\n",
    " ['R17', 'L03', 'R23', 'R19', 'M79', 'E14', 'E87', 'T14'],\n",
    " ['R06', 'R31', 'R19', 'A16', 'K92', 'R53', 'N93', 'D64'],\n",
    " ['R68', 'R30'],\n",
    " ['R52', 'R06', 'J45'],\n",
    " ['R11', 'R30', 'K59', 'R73', 'E14'],\n",
    " ['R06', 'R11', 'R07', 'R19', 'R09', 'R10', 'R34'],\n",
    " ['Z86', 'A16', 'R19', 'R53', 'E14'],\n",
    " ['R06', 'N40', 'I25', 'R19', 'R20', 'R52', 'T00'],\n",
    " ['R06', 'R11', 'R50', 'J45', 'R05'],\n",
    " ['N25', 'R52'],\n",
    " ['B99', 'K05'],\n",
    " ['R05', 'Z71', 'R19'],\n",
    " ['R11', 'R14', 'R19', 'K59', 'R10', 'E14'],\n",
    " ['M25', 'R06', 'R07', 'I25', 'R42'],\n",
    " ['R53'],\n",
    " ['R46', 'R69', 'R19', 'R40'],\n",
    " ['R52', 'N25'],\n",
    " [],\n",
    " ['R52', 'R29', 'R32', 'R19'],\n",
    " ['R10', 'R19'],\n",
    " ['R52', 'R06', 'Z92'],\n",
    " ['R52'],\n",
    " ['R52', 'K59', 'R19'],\n",
    " ['L02'],\n",
    " ['I48', 'R06', 'R11', 'R07', 'A16', 'T14', 'K92', 'R10'],\n",
    " ['Y09', 'S09', 'R19', 'A35'],\n",
    " ['L29', 'Z91'],\n",
    " ['N89'],\n",
    " ['R30'],\n",
    " ['R11', 'R53', 'R10'],\n",
    " ['R06', 'R07', 'T14', 'R52', 'M54'],\n",
    " ['N63', 'R53'],\n",
    " ['N25', 'S02', 'T14'],\n",
    " ['T14', 'R19', 'M79', 'S72', 'W01'],\n",
    " ['R22', 'R52', 'R11'],\n",
    " ['O03', 'N93'],\n",
    " ['R06', 'R68', 'R07', 'R19', 'R42', 'R53'],\n",
    " ['Y09', 'T01', 'R19', 'S49', 'M54', 'S42', 'R60', 'T14', 'A35'],\n",
    " ['R19', 'R52', 'K92', 'E14', 'K75', 'R18', 'R07', 'K59', 'K62', 'B18', 'R10'],\n",
    " ['R10', 'K59', 'R41'],\n",
    " ['R06', 'E03', 'R07', 'R19', 'R09'],\n",
    " ['N25', 'S09', 'S22', 'R52', 'B18', 'A35'],\n",
    " ['R19', 'K12', 'L29', 'A97', 'R57', 'R11', 'R50', 'R16', 'K59', 'B18'],\n",
    " [],\n",
    " ['R11', 'R50', 'K59', 'R19', 'B18', 'K75'],\n",
    " ['J03'],\n",
    " ['E87', 'R11', 'R10', 'D64'],\n",
    " ['T12', 'R09', 'R06', 'E87'],\n",
    " ['R52', 'R10'],\n",
    " ['O36', 'B37', 'N89'],\n",
    " ['R99'],\n",
    " ['N25', 'W01'],\n",
    " ['I44', 'E87', 'R68', 'R19', 'R53', 'R05'],\n",
    " ['A41', 'R63', 'R11'],\n",
    " ['R10'],\n",
    " ['N89', 'R42'],\n",
    " ['A16', 'R19', 'A09', 'E86', 'R63', 'R11', 'R07', 'K59', 'R40', 'R10'],\n",
    " ['R06', 'A16', 'R19', 'J45', 'M54'],\n",
    " ['N95', 'R06', 'R23', 'R07', 'D50', 'E14'],\n",
    " ['B83', 'E14'],\n",
    " ['R06'],\n",
    " ['R07'],\n",
    " ['R06', 'I25', 'R19', 'R09', 'Z86', 'R11', 'I50', 'R07', 'R00', 'B18', 'R05'],\n",
    " ['R00', 'R53'],\n",
    " ['R22', 'R06', 'A16', 'X51', 'R05'],\n",
    " ['R52', 'L98', 'M19', 'T14'],\n",
    " ['Z86', 'A16', 'R19', 'N92', 'R10', 'K76'],\n",
    " ['R06', 'R20', 'I63', 'R09', 'R05'],\n",
    " ['H93', 'R42'],\n",
    " ['R50', 'J45', 'R10', 'M54'],\n",
    " ['R06', 'A16', 'X51', 'Z86', 'I48', 'R11', 'R07', 'K29', 'T14', 'R10', 'K76'],\n",
    " ['K40', 'K59', 'R19'],\n",
    " ['S52', 'W10', 'T14'],\n",
    " [],\n",
    " ['R52', 'K81', 'K80', 'K59'],\n",
    " ['R29', 'E87', 'K52', 'E34', 'R53', 'R41'],\n",
    " ['R06', 'A16', 'R19', 'R09', 'B34'],\n",
    " ['R22', 'R06', 'R11', 'K29', 'R19', 'R10', 'E14', 'R05'],\n",
    " ['A16', 'R19', 'R52', 'K92', 'R10'],\n",
    " ['N25', 'R19', 'S09', 'T14', 'R42', 'S80', 'S00', 'A35'],\n",
    " ['O30', 'R35'],\n",
    " ['R52', 'E14'],\n",
    " ['R52', 'R22', 'R10'],\n",
    " ['R11', 'R19', 'R40', 'R10', 'E14'],\n",
    " ['R52'],\n",
    " [],\n",
    " ['N25', 'S82', 'T14', 'M79'],\n",
    " ['N25', 'S82'],\n",
    " ['R11', 'R18', 'R14', 'K59', 'R52', 'F90', 'K56'],\n",
    " ['R52'],\n",
    " ['N25', 'S62', 'T14'],\n",
    " ['E87', 'R06', 'R19'],\n",
    " ['R19', 'R11', 'G44', 'R51'],\n",
    " ['N05', 'O24', 'K51', 'R05'],\n",
    " ['S05', 'A35', 'Q10', 'T14'],\n",
    " ['R63', 'R11', 'R31', 'R19', 'R52', 'K59', 'R30'],\n",
    " ['R05', 'I48', 'R19', 'J69', 'R10', 'A09'],\n",
    " ['R40', 'T14', 'E04', 'R19'],\n",
    " ['N94', 'N92'],\n",
    " ['R06', 'R53', 'R07'],\n",
    " ['R22', 'R39', 'N20', 'R19', 'R52', 'K40'],\n",
    " ['N25', 'M79', 'R52', 'S42'],\n",
    " ['O24', 'B17', 'K75', 'R19'],\n",
    " [],\n",
    " ['R06', 'I25', 'R09', 'E14', 'R05'],\n",
    " ['R26', 'R11', 'R19'],\n",
    " ['L97', 'L29'],\n",
    " ['R06', 'R07', 'K59', 'R19', 'Z72', 'A09'],\n",
    " ['M25', 'R11', 'K59', 'R19'],\n",
    " ['R23', 'R52', 'M79', 'E14', 'M54', 'L29', 'R11', 'R07'],\n",
    " ['G04', 'Z88', 'R19', 'I25', 'R26', 'E14', 'R41', 'R68', 'A41'],\n",
    " ['R19', 'K92', 'E14', 'M54', 'I89', 'R11', 'R50', 'R59', 'B18', 'R10'],\n",
    " ['Q66', 'T13', 'T14'],\n",
    " ['Z71', 'R06', 'F22', 'R20', 'F99', 'K92', 'R44', 'R50', 'B18', 'R45'],\n",
    " ['E87', 'R00', 'R07', 'R19', 'I95', 'R55', 'R53', 'D64'],\n",
    " ['I48', 'D61', 'R06', 'I51', 'R19'],\n",
    " ['R50', 'K29', 'R19', 'N30', 'R10'],\n",
    " ['R68'],\n",
    " ['R09', 'R06', 'I25', 'R05'],\n",
    " ['R19', 'N13', 'R30', 'R10'],\n",
    " ['R22', 'R06', 'A16', 'R51', 'B02', 'I48', 'R60', 'R11', 'R07', 'K59'],\n",
    " ['R11', 'K59', 'R19', 'R52', 'K64'],\n",
    " ['R52', 'T14'],\n",
    " ['J98', 'R11', 'R07'],\n",
    " ['W01'],\n",
    " ['Z71', 'R06', 'R30', 'R52'],\n",
    " ['R22', 'N39', 'R11', 'R39', 'R31', 'R10'],\n",
    " ['N50'],\n",
    " ['R51', 'R11', 'T14', 'R52', 'M54'],\n",
    " ['A97', 'R06', 'R07', 'R50', 'R19'],\n",
    " ['R26'],\n",
    " ['R52', 'K56', 'R10', 'K59'],\n",
    " ['M79'],\n",
    " ['R11', 'R51', 'R55', 'B18', 'R10', 'E14'],\n",
    " [],\n",
    " ['R10', 'R00', 'R07']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "results_df['hopi_'] = test_df['HOPI_modified']\n",
    "results_df['approach_1'] = results\n",
    "results_df['approach_2'] = test_df['predicted'].apply(lambda x: x.split(\",\"))\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inter(x):\n",
    "    set1 = set(x['approach_1'])\n",
    "    set2 = set(x['approach_2'])\n",
    "    return set1.intersection(set2)\n",
    "\n",
    "results_df['intersection'] = results_df.apply(get_inter,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['approach_1'] = results_df['approach_1'].apply(lambda x: \",\".join(list(x)))\n",
    "results_df['approach_2'] = results_df['approach_2'].apply(lambda x: \",\".join(list(x)))\n",
    "results_df['intersection'] = results_df['intersection'].apply(lambda x: \",\".join(list(x)))\n",
    "\n",
    "results_df.to_csv('results.csv',index=False)\n",
    "results_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['med','icd','all']\n",
    "stop_words = ['english',None] \n",
    "feature_length = [5,10,25]\n",
    "sl_count = range(1,11)\n",
    "metrics = ['cosine','euclidean','chebyshev','minkowski','manhattan']\n",
    "levels = ['l1','l2','l3']\n",
    "icd_desc = ['all','one']\n",
    "\n",
    "delim = \"$$$\"\n",
    "thresholds = [0.05,0.1,0.15,0.2,0.25,0.3,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text):\n",
    "    if not(type(text) is str):\n",
    "        return \"\"\n",
    "    doc = text.split(\"\\n\")\n",
    "    sents = []\n",
    "    for d in doc:\n",
    "        tokens = d.split(' ')\n",
    "        s = []\n",
    "        for t in tokens:\n",
    "            word = t.lower()\n",
    "            if word in med_dict.keys():\n",
    "                word = med_dict[word]\n",
    "            s.append(word)\n",
    "        s = \" \".join(s)\n",
    "        s = re.sub(r'[^\\w\\s]', '', s).strip()\n",
    "        sents.append(s)\n",
    "    sents = list(filter(lambda x: len(x) > 0,sents))\n",
    "    sents = list(filter(lambda x: type(x) is str,sents))\n",
    "    return  delim.join(sents)\n",
    "\n",
    "def getICDCodes(level,desc):\n",
    "    l = levels.index(level)\n",
    "    all_codes = icd.get_all_codes(with_dots=True)\n",
    "    code_df = pd.DataFrame(all_codes,columns=['code'])\n",
    "    code_df['description'] = code_df['code'].apply(lambda x: icd.get_description(x))\n",
    "    code_df['ancestor'] = code_df['code'].apply(lambda x: icd.get_ancestors(x))\n",
    "    code_df['descendants'] = code_df['code'].apply(lambda x: icd.get_descendants(x))\n",
    "    \n",
    "    filtered = code_df[code_df.apply(lambda x: len(x['ancestor']),axis=1) == l]\n",
    "    filtered = filtered.drop_duplicates(['description'])\n",
    "    filtered = filtered.reset_index(drop=True)\n",
    "        \n",
    "    if desc == 'all':\n",
    "        for c in filtered.iterrows():\n",
    "            desc = [filtered.loc[c[0]].description]\n",
    "            for d in c[1]['descendants']:\n",
    "                desc.append(icd.get_description(d))\n",
    "            filtered.loc[c[0]].description = \" \".join(desc)\n",
    "            \n",
    "        filtered = filtered.drop('description', axis=1).join(filtered['description'].str.split('$', expand=True).stack().reset_index(level=1, drop=True).rename('description'))\n",
    "        filtered.drop(['ancestor','descendants'],axis=1,inplace=True)\n",
    "        filtered.reset_index(inplace=True)\n",
    "            \n",
    "    return filtered\n",
    "\n",
    "\n",
    "def getVectorizer(corpus,stop_words,records,description):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "    if corpus == 'med':\n",
    "        vectorizer.fit(records)\n",
    "    if corpus == 'icd':\n",
    "        vectorizer.fit(description)\n",
    "    if corpus == 'all':\n",
    "        vectorizer.fit(pd.concat([records,description]))\n",
    "    \n",
    "    return vectorizer\n",
    "\n",
    "# def get_labels(i,n,dist,filtered):\n",
    "#     nearest = list(zip(np.sort(dist)[i,:n],np.argsort(dist)[i,:n]))\n",
    "#     temp = list()\n",
    "#     for j in nearest:\n",
    "#         code = filtered[j[1]]\n",
    "#         temp.append(code)\n",
    "        \n",
    "#     return \",\".join(temp)\n",
    "\n",
    "def get_labels(doc, vectorizer,tsvd,test_vectors,metric,filtered,threshold):\n",
    "    docs = doc.split(delim)\n",
    "    doc_vectors = vectorizer.transform(docs)\n",
    "    doc_vectors = tsvd.transform(doc_vectors)\n",
    "    \n",
    "    dist = pairwise_distances(doc_vectors,test_vectors,metric=metric)\n",
    "    \n",
    "    n=1 #suggested words\n",
    "    temp = []\n",
    "    for j in range(len(docs)):\n",
    "        nearest = list(zip(np.sort(dist)[j,:n],np.argsort(dist)[j,:n]))\n",
    "        for k in nearest:\n",
    "            code = filtered[k[1]]\n",
    "            if k[0] < threshold:\n",
    "                temp.append(code)\n",
    "        \n",
    "    return \",\".join(temp)\n",
    "\n",
    "def getAncestors(x,level):\n",
    "    if not(x is str):\n",
    "        x = str(x)\n",
    "    \n",
    "    index = int(level[-1])\n",
    "    codes = x.split(',')\n",
    "    temp = list()\n",
    "    for c in codes:\n",
    "        i = c.strip()\n",
    "        while(len(i) > 0 and not(icd.is_valid_item(i))):\n",
    "            i = i[:-1]\n",
    "        \n",
    "        if len(i) == 0:\n",
    "            continue \n",
    "        if len(icd.get_ancestors(i)) < index:\n",
    "            temp.append(i)\n",
    "        else:\n",
    "            i = icd.get_ancestors(i)[-index]\n",
    "        temp.append(i)\n",
    "    \n",
    "    \n",
    "    return \",\".join(temp)\n",
    "\n",
    "def getScores(actual,predicted):\n",
    "    recall = []\n",
    "    precision = []\n",
    "    f_score = []\n",
    "\n",
    "    for i in range(test_df.shape[0]):\n",
    "        s1 = set(actual[i].split(\",\"))\n",
    "        s2 = set(predicted[i].split(\",\"))\n",
    "\n",
    "        inter = len(s1.intersection(s2))\n",
    "        r = inter/len(s1)\n",
    "        recall.append(r)\n",
    "        p = inter/len(s2)\n",
    "        precision.append(p)\n",
    "\n",
    "        try:\n",
    "            f_score.append(2 * r * p/(r + p))\n",
    "        except:\n",
    "            f_score.append(0)\n",
    "        \n",
    "    test_df['recall'] = recall\n",
    "    test_df['precision'] = precision\n",
    "    test_df['f_score'] = f_score\n",
    "\n",
    "    avg_recall = test_df['recall'].mean()\n",
    "    avg_prec = test_df['precision'].mean()\n",
    "    avg_f_score = test_df['f_score'].mean()\n",
    "    \n",
    "    return (avg_recall,avg_prec,avg_f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_dict = pd.read_excel(r'Data\\medicalTermsDictionary (1).xlsx')\n",
    "med_dict = dict(zip(med_dict.Abbreviation, med_dict.Term))\n",
    "\n",
    "test_df = pd.read_excel(r'Data\\Sample_HOPI.xlsx')\n",
    "test_df['HOPI_modified'] = test_df['hopi_'].apply(lambda x: transformText(x))\n",
    "test_df = test_df[test_df['HOPI_modified'].notna()]\n",
    "\n",
    "df = pd.read_excel(r'Data/data.xlsx')\n",
    "grid_df = pd.DataFrame(columns=['level','icd_desc','corpus','stop_words','feature_length','metric','threshold','recall','precision','f_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None               5  cosine       0.05   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.029227   0.010235  0.014149  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None               5  cosine        0.1   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.032129   0.009466  0.013668  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None               5  cosine       0.15   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.032129   0.009448  0.013644  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None               5  cosine        0.2   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.032129   0.009448  0.013644  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None               5  cosine       0.25   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.032129   0.009448  0.013644  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None               5  cosine        0.3   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.032129   0.009448  0.013644  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None               5  cosine        0.5   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.032129   0.009448  0.013644  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None               5  cosine       0.75   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.032129   0.009448  0.013644  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None               5  cosine          1   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.032129   0.009448  0.013644  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  euclidean       0.05   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.025296   0.014829  0.017783  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  euclidean        0.1   \n",
      "\n",
      "    recall  precision  f_score  \n",
      "0  0.02712   0.012456   0.0162  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  euclidean       0.15   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.02795    0.01095  0.015334  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  euclidean        0.2   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.02795   0.010711  0.015071  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  euclidean       0.25   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.02795    0.01059  0.014951  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  euclidean        0.3   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.02795   0.010528  0.014891  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  euclidean        0.5   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.02795   0.010503  0.014861  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  euclidean       0.75   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.02795   0.010503  0.014861  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  euclidean          1   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.02795   0.010503  0.014861  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  chebyshev       0.05   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.027748   0.012991  0.016524  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  chebyshev        0.1   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.031112    0.01128  0.015873  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  chebyshev       0.15   \n",
      "\n",
      "   recall  precision   f_score  \n",
      "0  0.0336   0.011075  0.015899  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  chebyshev        0.2   \n",
      "\n",
      "   recall  precision   f_score  \n",
      "0  0.0336   0.010973  0.015795  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  chebyshev       0.25   \n",
      "\n",
      "   recall  precision   f_score  \n",
      "0  0.0336   0.010973  0.015795  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  chebyshev        0.3   \n",
      "\n",
      "   recall  precision   f_score  \n",
      "0  0.0336   0.010973  0.015795  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  chebyshev        0.5   \n",
      "\n",
      "   recall  precision   f_score  \n",
      "0  0.0336   0.010692  0.015517  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  chebyshev       0.75   \n",
      "\n",
      "   recall  precision   f_score  \n",
      "0  0.0336   0.010692  0.015517  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  chebyshev          1   \n",
      "\n",
      "   recall  precision   f_score  \n",
      "0  0.0336   0.010692  0.015517  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  minkowski       0.05   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.025296   0.014829  0.017783  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  minkowski        0.1   \n",
      "\n",
      "    recall  precision  f_score  \n",
      "0  0.02712   0.012456   0.0162  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  minkowski       0.15   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.02795    0.01095  0.015334  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  minkowski        0.2   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.02795   0.010711  0.015071  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  minkowski       0.25   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.02795    0.01059  0.014951  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  minkowski        0.3   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.02795   0.010528  0.014891  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  minkowski        0.5   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.02795   0.010503  0.014861  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  minkowski       0.75   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.02795   0.010503  0.014861  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  minkowski          1   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.02795   0.010503  0.014861  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  manhattan       0.05   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.02442   0.020829  0.020927  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  manhattan        0.1   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.026824   0.014584  0.017862  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  manhattan       0.15   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.027819   0.013063  0.016752  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  manhattan        0.2   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.031716   0.012807  0.017553  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  manhattan       0.25   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.032546   0.012346  0.017399  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  manhattan        0.3   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.032546   0.011943  0.016975  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  manhattan        0.5   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.032546   0.011659  0.016689  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  manhattan       0.75   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.033375   0.011841  0.016993  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None               5  manhattan          1   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.03437   0.011708  0.017028  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              10  cosine       0.05   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.01194   0.012231  0.011246  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              10  cosine        0.1   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.015381   0.009791  0.010792  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              10  cosine       0.15   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.019456   0.008466  0.011044  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              10  cosine        0.2   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.028052   0.008654  0.012608  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              10  cosine       0.25   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.029047   0.008173  0.012268  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              10  cosine        0.3   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.030706   0.008259  0.012568  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              10  cosine        0.5   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.030706   0.008113  0.012393  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              10  cosine       0.75   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.030706   0.008113  0.012393  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              10  cosine          1   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.030706   0.008113  0.012393  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  euclidean       0.05   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.029697   0.033067  0.029123  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  euclidean        0.1   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.041607   0.023217  0.027794  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  euclidean       0.15   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.046334   0.017636  0.024486  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  euclidean        0.2   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.048987   0.016176  0.023636  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  euclidean       0.25   \n",
      "\n",
      "     recall  precision  f_score  \n",
      "0  0.048987   0.015555  0.02297  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  euclidean        0.3   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.048987   0.015381  0.022767  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  euclidean        0.5   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.048987    0.01496  0.022304  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  euclidean       0.75   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.048987   0.014884  0.022218  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  euclidean          1   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.048987   0.014884  0.022218  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  chebyshev       0.05   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.031416   0.018129  0.021405  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  chebyshev        0.1   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.033371    0.01223  0.017173  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  chebyshev       0.15   \n",
      "\n",
      "     recall  precision  f_score  \n",
      "0  0.033371   0.010243  0.01521  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  chebyshev        0.2   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.033371   0.010159  0.015107  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  chebyshev       0.25   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.033371   0.009961  0.014867  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  chebyshev        0.3   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.033371    0.00979  0.014702  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  chebyshev        0.5   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.033371   0.009531  0.014416  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  chebyshev       0.75   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.033371   0.009531  0.014416  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  chebyshev          1   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.033371   0.009531  0.014416  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  minkowski       0.05   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.029697   0.033067  0.029123  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  minkowski        0.1   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.041607   0.023217  0.027794  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  minkowski       0.15   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.046334   0.017636  0.024486  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  minkowski        0.2   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.048987   0.016176  0.023636  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  minkowski       0.25   \n",
      "\n",
      "     recall  precision  f_score  \n",
      "0  0.048987   0.015555  0.02297  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  minkowski        0.3   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.048987   0.015381  0.022767  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  minkowski        0.5   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.048987    0.01496  0.022304  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  minkowski       0.75   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.048987   0.014884  0.022218  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  minkowski          1   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.048987   0.014884  0.022218  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  manhattan       0.05   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.018574    0.02073  0.019249  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  manhattan        0.1   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.020114    0.02426  0.021046  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  manhattan       0.15   \n",
      "\n",
      "    recall  precision  f_score  \n",
      "0  0.02779   0.021679  0.02332  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  manhattan        0.2   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.032765   0.020342  0.023692  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  manhattan       0.25   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.034589   0.018976  0.022841  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  manhattan        0.3   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.037657   0.018789  0.023661  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  manhattan        0.5   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.04429   0.013412  0.020099  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  manhattan       0.75   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.04429   0.012704  0.019242  \n",
      "  level icd_desc corpus stop_words  feature_length     metric  threshold  \\\n",
      "0    l3      one    med       None              10  manhattan          1   \n",
      "\n",
      "    recall  precision   f_score  \n",
      "0  0.04429   0.012639  0.019168  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              25  cosine       0.05   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.014262    0.01675  0.014688  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              25  cosine        0.1   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.011526   0.013682  0.011783  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              25  cosine       0.15   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.022056   0.022659  0.021194  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              25  cosine        0.2   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.039469   0.023022  0.027016  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              25  cosine       0.25   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.045155   0.023889  0.028316  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              25  cosine        0.3   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.048887   0.020603  0.027422  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              25  cosine        0.5   \n",
      "\n",
      "     recall  precision  f_score  \n",
      "0  0.064321   0.016368  0.02504  \n",
      "  level icd_desc corpus stop_words  feature_length  metric  threshold  \\\n",
      "0    l3      one    med       None              25  cosine       0.75   \n",
      "\n",
      "     recall  precision   f_score  \n",
      "0  0.064321    0.01613  0.024777  \n"
     ]
    }
   ],
   "source": [
    "for l in levels:  \n",
    "    for d in icd_desc:\n",
    "        codes = getICDCodes(l,d) \n",
    "        test_df['code_modified'] = test_df['code'].apply(lambda x: getAncestors(x,l))\n",
    "        for c in corpus:\n",
    "            for s in stop_words:\n",
    "                vectorizer = getVectorizer(c,s,df['HOPI_modified'],codes['description'])\n",
    "                icd_vec = vectorizer.transform(codes['description']).toarray()\n",
    "                hopi_vec = vectorizer.transform(test_df['HOPI_modified']).toarray()\n",
    "                clear_output(wait=True)\n",
    "                for f in feature_length:\n",
    "                    doc_vectors = csr_matrix(hopi_vec)\n",
    "                    tsvd = TruncatedSVD(n_components=f)\n",
    "                    _ = tsvd.fit(doc_vectors)\n",
    "                    doc_vectors = tsvd.transform(doc_vectors)\n",
    "                    test_vectors = tsvd.transform(csr_matrix(icd_vec))\n",
    "                    \n",
    "                    for m in metrics:\n",
    "                        for t in thresholds:    \n",
    "                            predictions = [get_labels(doc,vectorizer,tsvd,test_vectors,m,codes['code'],t) for doc in test_df['HOPI_modified']]\n",
    "                            scores = getScores(test_df['code_modified'],predictions)\n",
    "                            \n",
    "                            row = pd.DataFrame([[l,d,c,s,f,m,t,scores[0],scores[1],scores[2]]], columns=grid_df.columns)\n",
    "                            grid_df = pd.concat([grid_df,row])\n",
    "                            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df.to_excel('grid_search_lemma.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in levels:  \n",
    "    for d in icd_desc:\n",
    "        codes = getICDCodes(l,d) \n",
    "        test_df['code_modified'] = test_df['code'].apply(lambda x: getAncestors(x,l))\n",
    "        for c in corpus:\n",
    "            for s in stop_words:\n",
    "                vectorizer = getVectorizer(c,s,df['HOPI_modified'],codes['description'])\n",
    "                icd_vec = vectorizer.transform(codes['description']).toarray()\n",
    "                hopi_vec = vectorizer.transform(test_df['HOPI_modified']).toarray()\n",
    "                clear_output(wait=True)\n",
    "                for f in feature_length:\n",
    "                    doc_vectors = csr_matrix(hopi_vec)\n",
    "                    tsvd = TruncatedSVD(n_components=f)\n",
    "                    _ = tsvd.fit(doc_vectors)\n",
    "                    doc_vectors = tsvd.transform(doc_vectors)\n",
    "                    test_vectors = tsvd.transform(csr_matrix(icd_vec))\n",
    "                    \n",
    "                    for m in metrics:\n",
    "                        dist = pairwise_distances(doc_vectors,test_vectors,metric=m)\n",
    "                        \n",
    "                        for sl in sl_count:  \n",
    "                            predictions = [get_labels(i,sl,dist,codes['code']) for i in range(0,test_df.shape[0])]\n",
    "                            scores = getScores(test_df['code_modified'],predictions)\n",
    "                            \n",
    "                            row = pd.DataFrame([[l,d,c,s,f,sl,m,scores[0],scores[1],scores[2]]], columns=grid_df.columns)\n",
    "                            grid_df = pd.concat([grid_df,row])\n",
    "                            print(row)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "745acbd60b3d3a97c5945352b8ea4157d78b838f777f5ff9015d2ad09d6a6d28"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
